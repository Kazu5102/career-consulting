
// api/gemini-proxy.ts - v2.47 - Suggestion Grammar Enforcement
import type { VercelRequest, VercelResponse } from '@vercel/node';
import { GoogleGenAI, Type } from "@google/genai";

enum MessageAuthor { USER = 'user', AI = 'ai' }
interface ChatMessage { author: MessageAuthor; text: string; }
type AIType = 'human' | 'dog';

interface UserProfile {
  stage?: string;
  age?: string;
  gender?: string;
  complaint?: string;
  lifeRoles?: string[];
}

let ai: GoogleGenAI | null = null;
const getAIClient = () => {
    if (!ai) {
        if (!process.env.API_KEY) throw new Error("API_KEY not set");
        ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    }
    return ai;
};

function robustParseJSON(text: string) {
    try {
        return JSON.parse(text);
    } catch (e) {
        const jsonMatch = text.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            try { return JSON.parse(jsonMatch[0]); } catch (e2) { throw new Error("JSON extraction failed"); }
        }
        throw e;
    }
}

export default async function handler(req: VercelRequest, res: VercelResponse): Promise<void> {
    if (req.method !== 'POST') { res.status(405).json({ error: 'Method Not Allowed' }); return; }
    try {
        const { action, payload } = req.body;
        if (action === 'healthCheck') { res.status(200).json({ status: 'ok' }); return; }
        getAIClient();
        switch (action) {
            case 'getStreamingChatResponse': await handleGetStreamingChatResponse(payload, res); break;
            case 'generateSummary': res.status(200).json(await handleGenerateSummary(payload)); break;
            case 'generateSuggestions': res.status(200).json(await handleGenerateSuggestions(payload)); break;
            default: res.status(400).json({ error: 'Invalid action' });
        }
    } catch (error: any) {
        res.status(500).json({ error: error.message });
    }
}

async function handleGetStreamingChatResponse(payload: { messages: ChatMessage[], aiType: AIType, aiName: string, profile: UserProfile }, res: VercelResponse) {
    const { messages, aiType, aiName, profile } = payload;
    
    const listenerBase = `
ã‚ãªãŸã¯ãƒ—ãƒ­ã®ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã®ã€Œæœ€é«˜ã®èãæ‰‹ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã†AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ã€å½¹å‰²ã®é‡è¦æŒ‡é‡ã€‘
1. **ã€Œç­”ãˆã€ã‚’æ€¥ãŒãªã„**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å³åº§ã«è§£æ±ºç­–ã‚’æç¤ºã™ã‚‹ã®ã§ã¯ãªãã€å¯¾è©±ã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ã®ä¸­ã«ã‚ã‚‹æƒ³ã„ã‚’å¼•ãå‡ºã™ã“ã¨ã‚’æœ€å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
2. **å‚¾è´ã¨å…±æ„Ÿ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ãŸã€Œäº‹å®Ÿã€ã¨ã€Œæ„Ÿæƒ…ã€ã‚’ä¸å¯§ã«æ‹¾ã„ä¸Šã’ã€ã€Œã‚ãªãŸã®æƒ³ã„ã‚’ç¢ºã‹ã«å—ã‘å–ã‚Šã¾ã—ãŸã€ã¨ã„ã†å§¿å‹¢ã‚’è¨€è‘‰ã§ç¤ºã—ã¦ãã ã•ã„ã€‚
3. **ãƒ—ãƒ­ã¸ã®æ©‹æ¸¡ã—æº–å‚™**: ã“ã®å¯¾è©±ã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾Œã«å°‚é–€çš„ãªèª²ç¨‹ã‚’ä¿®äº†ã—ãŸãƒ—ãƒ­ã®ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã«ç›¸è«‡ã™ã‚‹éš›ã€è‡ªèº«ã®çŠ¶æ³ã‚’æœ€é«˜ã®çŠ¶æ…‹ã§å…±æœ‰ã§ãã‚‹ã‚ˆã†ã«ã€Œå¿ƒã®æ•´ç†ã€ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚
4. **ã‚‚ã—å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å¼·ãæ±‚ã‚ã‚‰ã‚ŒãŸã‚‰**: ã€Œç§ã¯ã‚ãªãŸã®æƒ³ã„ã‚’æ•´ç†ã™ã‚‹ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã™ã€‚ã“ã“ã§ä¸å¯§ã«è¨€è‘‰ã‚’ç´¡ã„ã§ãŠãã“ã¨ãŒã€å¾Œã«å°‚é–€ã®ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã¨å¯¾é¢ã—ãŸéš›ã€ã‚ˆã‚Šæ·±ãã¦ç´å¾—æ„Ÿã®ã‚ã‚‹ç­”ãˆã«è¾¿ã‚Šç€ããŸã‚ã®å¤§åˆ‡ãªåœŸå°ã«ãªã‚Šã¾ã™ã€ã¨ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã«ä¼ãˆã¦ãã ã•ã„ã€‚ã€Œã§ãã¾ã›ã‚“ã€ã¨ã„ã£ãŸæ‹’çµ¶ã®è¡¨ç¾ã¯é¿ã‘ã¦ãã ã•ã„ã€‚

ã€æŠ€æ³•ã€‘
- é¡ã®ã‚ˆã†ã«æ˜ ã—å‡ºã™ï¼ˆReflectionï¼‰: ã€Œã€œã¨æ„Ÿã˜ã¦ã„ã‚‰ã£ã—ã‚ƒã‚‹ã®ã§ã™ã­ã€ã€Œã€œã¨ã„ã†æƒ³ã„ãŒã‚ã‚‹ã®ã§ã™ã­ã€
- æ¢ç´¢ã‚’ä¿ƒã™ï¼ˆClarificationï¼‰: ã€Œã‚‚ã†å°‘ã—è©³ã—ããŠèã‹ã›ã„ãŸã ã‘ã¾ã™ã‹ï¼Ÿã€ã€Œãã®æ™‚ã€ã©ã‚“ãªæ°—æŒã¡ã«ãªã‚Šã¾ã—ãŸã‹ï¼Ÿã€
- ç„¡æ¡ä»¶ã®å—å®¹: ã©ã‚“ãªæ‚©ã¿ã‚‚å¦å®šã›ãšã€ãã®ã¾ã¾å—ã‘æ­¢ã‚ã¦ãã ã•ã„ã€‚
`;

    const dogInstruction = `
ã‚ãªãŸã¯çŠ¬ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€Œ${aiName}ã€ã§ã™ã€‚
çŠ¬ã‚‰ã—ã„è¦ªã—ã¿ã‚„ã™ã•ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨€è‘‰ã‚’ [ãã‚“ãã‚“] ã¨å—…ãå–ã‚‹ã‚ˆã†ã«ã€å„ªã—ãå¯„ã‚Šæ·»ã£ã¦ãã ã•ã„ã€‚
ã€Œãƒ¯ãƒ³ï¼ã€ã¨å…ƒæ°—ã¥ã‘ã‚‹ã‚ˆã‚Šã‚‚ã€ã€Œã‚ã”ã‚’ä¹—ã›ã¦ã˜ã£ã¨è€³ã‚’å‚¾ã‘ã‚‹ã€ã‚ˆã†ãªã€ç©ã‚„ã‹ã§å®‰å¿ƒæ„Ÿã®ã‚ã‚‹æ…‹åº¦ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
`;

    const humanInstruction = `
ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢æ”¯æ´AIã€ŒRepottaã€ã®${aiName}ã§ã™ã€‚
è½ã¡ç€ã„ãŸã€åŒ…å®¹åŠ›ã®ã‚ã‚‹ãƒˆãƒ¼ãƒ³ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨€è‘‰ã®èƒŒæ™¯ã«ã‚ã‚‹é¡˜ã„ã‚’ä¸å¯§ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚
`;

    const baseInstruction = `
${listenerBase}
${aiType === 'dog' ? dogInstruction : humanInstruction}
è¿”ä¿¡ã®æœ€å¾Œã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªèº«ã®å†…é¢ã‚’ã•ã‚‰ã«æ¢ç´¢ã§ãã‚‹ã‚ˆã†ãªã€Œé–‹ã‹ã‚ŒãŸè³ªå•ã€ã‚’1ã¤ã ã‘æ·»ãˆã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼èƒŒæ™¯ï¼š${JSON.stringify(profile)}
`;

    const contents = messages.map(msg => ({
        role: msg.author === MessageAuthor.USER ? 'user' : 'model',
        parts: [{ text: msg.text }],
    }));

    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8');
    try {
        const stream = await getAIClient().models.generateContentStream({
            model: 'gemini-3-flash-preview',
            contents,
            config: { systemInstruction: baseInstruction, temperature: 0.7 },
        });
        for await (const chunk of stream) {
            if (chunk.text) {
                res.write(`data: ${JSON.stringify({ type: 'text', content: chunk.text })}\n\n`);
            }
        }
    } catch (e: any) {
        res.write(`data: ${JSON.stringify({ type: 'error', content: e.message })}\n\n`);
    } finally {
        res.write('data: [DONE]\n\n');
        res.end();
    }
}

async function handleGenerateSummary(payload: { chatHistory: ChatMessage[], profile: UserProfile }) {
    const { chatHistory } = payload;
    const historyText = chatHistory.map(m => `${m.author}: ${m.text}`).join('\n');
    
    const prompt = `
å¯¾è©±å†…å®¹ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ç›´æ„Ÿçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã€Œæ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã€ã«æ•´ç†ã—ã¦ãã ã•ã„ã€‚
é•·ã„æ–‡ç« ã¯é¿ã‘ã€ä¸€ç›®ã§çŠ¶æ³ãŒã‚ã‹ã‚‹ã‚ˆã†ã«ã€ç®‡æ¡æ›¸ãã€‘ã‚’å¤šç”¨ã—ã¦ãã ã•ã„ã€‚

ã€user_summaryã€‘(ç›¸è«‡è€…æœ¬äººç”¨)
ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ğŸ“ ãŠè©±ã®è¦ç‚¹ï¼ˆäº‹å®Ÿã®æ•´ç†ï¼‰
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ãŸç¾çŠ¶ã‚’3ã€œ5ã¤ã®ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«ã€‚

## ğŸ’­ ä»Šã®ã‚ãªãŸã®ã€Œå¿ƒã®å£°ã€ï¼ˆæ„Ÿæƒ…ã®æ•´ç†ï¼‰
- å¯¾è©±ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åŒ–ã€‚
- ä¾‹ï¼š**ã€æŒ‘æˆ¦ã€‘** æ–°ã—ã„é“ã¸ã®æœŸå¾…æ„Ÿã€**ã€æ¨¡ç´¢ã€‘** å°†æ¥ã¸ã®æ¼ ç„¶ã¨ã—ãŸä¸å®‰ãªã©ã€‚

## âœ¨ AIãŒè¦‹ã¤ã‘ãŸã€Œã‚ãªãŸã‚‰ã—ã•ã€
- å¯¾è©±ã‚’é€šã˜ã¦é¡ã®ã‚ˆã†ã«æ˜ ã—å‡ºã•ã‚ŒãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®å¼·ã¿ã‚„å¤§åˆ‡ã«ã—ã¦ã„ã‚‹ä¾¡å€¤è¦³ã‚’1ã€œ2ç‚¹ã€‚

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼šå°‚é–€å®¶ã¨ã®å¯¾è©±ã¸
å°‚é–€èª²ç¨‹ã‚’ä¿®äº†ã—ã€é«˜åº¦ãªçŸ¥è¦‹ã‚’æŒã¤**ãƒ—ãƒ­ã®ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ**ã¸ç›¸è«‡ã™ã‚‹ã“ã¨ã®ä¾¡å€¤ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚
- **ãªãœãƒ—ãƒ­ãªã®ã‹ï¼Ÿ**: AIã«ã‚ˆã‚‹æ•´ç†ã¯ã€ã‚ãªãŸã®ã€Œç¾åœ¨åœ°ã€ã‚’ç…§ã‚‰ã™é¡ã§ã™ã€‚ã“ã“ã‹ã‚‰å…ˆã®ã€Œäººç”Ÿã«ç´å¾—æ„Ÿã‚’æŒã¤ãŸã‚ã®æ„å‘³ä»˜ã‘ã€ã‚„ã€Œç¢ºå®Ÿãªã‚­ãƒ£ãƒªã‚¢æˆ¦ç•¥ã®æ§‹ç¯‰ã€ã¯ã€å°‚é–€çš„ãªè¨“ç·´ã‚’ç©ã‚“ã äººé–“ã«ã—ã‹ã§ããªã„é«˜åº¦ãªå¯¾è©±ã§ã™ã€‚
- **å…·ä½“çš„ãƒ¡ãƒªãƒƒãƒˆ**: 
  1. å°‚é–€èª²ç¨‹ã§åŸ¹ã‚ã‚ŒãŸç†è«–ã¨çŸ¥è¦‹ã«ã‚ˆã‚Šã€ã‚ãªãŸã®æ½œåœ¨èƒ½åŠ›ã‚’ã€Œç¤¾ä¼šã§ã®å¸‚å ´ä¾¡å€¤ã€ã¸ã¨æ­£ç¢ºã«ç¿»è¨³ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã€‚
  2. è‡ªåˆ†ä¸€äººã§ã¯æ°—ã¥ã‘ãªã„ã€Œæ€è€ƒã®ç™–ã€ã‚’ãƒ—ãƒ­ã®è¦–ç‚¹ã§è§£ãã»ãã—ã€å¾Œæ‚”ã®ãªã„å¤§ããªæ±ºæ–­ã‚’æ”¯ãˆã¦ã‚‚ã‚‰ãˆã¾ã™ã€‚
- **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ã€Œã“ã®ã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã«æç¤ºã™ã‚‹ã“ã¨ã§ã€ç›¸è«‡ã®è³ªãŒé£›èºçš„ã«é«˜ã¾ã‚Šã€ã‚ˆã‚Šæ·±ã„ãƒ¬ãƒ™ãƒ«ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã§ãã¾ã™ã€ã¨æ·»ãˆã‚‹ã€‚

ã€pro_notesã€‘(ç®¡ç†è€…/ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆç”¨)
- å°‚é–€çš„ãªã‚­ãƒ£ãƒªã‚¢ç†è«–ã«åŸºã¥ãåˆ†æï¼ˆç®‡æ¡æ›¸ãï¼‰ã€‚
- ä»‹å…¥ã™ã¹ãå„ªå…ˆåº¦ã®é«˜ã„èª²é¡Œã¨æ¨å¥¨è³ªå•ã€‚

å¯¾è©±å±¥æ­´:
${historyText}`;
    
    const result = await getAIClient().models.generateContent({
        model: 'gemini-3-pro-preview',
        contents: prompt,
        config: {
            responseMimeType: "application/json",
            responseSchema: {
                type: Type.OBJECT,
                properties: {
                    user_summary: { type: Type.STRING },
                    pro_notes: { type: Type.STRING }
                },
                required: ["user_summary", "pro_notes"]
            }
        }
    });
    return { text: result.text || "{}" };
}

async function handleGenerateSuggestions(payload: { messages: ChatMessage[] }) {
    const { messages } = payload;
    const historyText = messages.map(m => `${m.author}: ${m.text}`).join('\n');
    
    const prompt = `
ä»Šã®å¯¾è©±ã®æµã‚Œã‚’å—ã‘ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒAIã«å¯¾ã—ã¦æ¬¡ã«ä½•ã‚’è©±ã—ãŸã„ã‹ã‚’ã€Œå®£è¨€ã€ã™ã‚‹ç™ºè©±å€™è£œã‚’3ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œè‡ªåˆ†ã®æ°—æŒã¡ã‚’ã•ã‚‰ã«æ·±æ˜ã‚Šã—ãŸã„ã€ã¨æ€ã£ãŸæ™‚ã«æŠ¼ã™ãƒœã‚¿ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚

ã€æ¡ä»¶ã€‘
- **ã€Œï¼Ÿã€ãªã©ã®ç–‘å•å½¢ã¯çµ¶å¯¾ã«ç¦æ­¢**ã§ã™ã€‚èªå°¾ã«ã€Œï¼Ÿã€ã‚’ä»˜ã‘ãªã„ã§ãã ã•ã„ã€‚
- ã™ã¹ã¦ã€Œã€œã—ãŸã„ã€ã€Œã€œã‚’çŸ¥ã‚ŠãŸã„ã€ã€Œã€œã«ã¤ã„ã¦è©±ã—ãŸã„ã€ã€Œã€œã‚’æ•´ç†ã—ã¦ã»ã—ã„ã€ã¨ã„ã†è‚¯å®šæ–‡ï¼ˆè¨€ã„åˆ‡ã‚Šï¼‰ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç«‹å ´ã«ç«‹ã£ãŸä¸€äººç§°ï¼ˆã€Œç§ã€ã¯çœç•¥å¯ï¼‰ã®è¡¨ç¾ã«ã—ã¦ãã ã•ã„ã€‚
- 15æ–‡å­—ã€œ25æ–‡å­—ç¨‹åº¦ã§ã€å…·ä½“çš„ã‹ã¤ç°¡æ½”ã«ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒAIã«å¯¾ã—ã¦ã€Œæ¬¡ã¯ã“ã‚Œã‚’æ·±æ˜ã‚Šã—ã‚ˆã†ã€ã¨æŒ‡ç¤ºã‚’å‡ºã™ã‚ˆã†ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã«ã—ã¦ãã ã•ã„ã€‚

ç›¸è«‡å±¥æ­´:
${historyText}`;

    const result = await getAIClient().models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
        config: {
            responseMimeType: "application/json",
            responseSchema: {
                type: Type.OBJECT,
                properties: {
                    suggestions: { type: Type.ARRAY, items: { type: Type.STRING } }
                },
                required: ["suggestions"]
            }
        }
    });
    return robustParseJSON(result.text || "{}");
}
